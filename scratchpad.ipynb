{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 13:53:00.557773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-05 13:53:14.166363: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-05 13:53:14.166550: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-05 13:53:14.166568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from neurallogic import neural_logic_net, harden, harden_layer, hard_or, hard_and, hard_not, primitives\n",
    "from tests import test_mnist\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax._src.util import safe_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.interpreters import xla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandpit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_jaxpr(closed_jaxpr):\n",
    "   jaxpr = closed_jaxpr.jaxpr\n",
    "   print(\"invars:\", jaxpr.invars)\n",
    "   print(\"outvars:\", jaxpr.outvars)\n",
    "   print(\"constvars:\", jaxpr.constvars)\n",
    "   for eqn in jaxpr.eqns:\n",
    "     print(\"equation:\", eqn.invars, eqn.primitive, eqn.outvars, eqn.params)\n",
    "   print()\n",
    "   print(\"jaxpr:\", jaxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = test_mnist.get_datasets()\n",
    "train_ds[\"image\"] = jnp.reshape(train_ds[\"image\"], (train_ds[\"image\"].shape[0], -1))\n",
    "test_ds[\"image\"] = jnp.reshape(test_ds[\"image\"], (test_ds[\"image\"].shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nln(type, x, width):\n",
    "    x = hard_or.or_layer(type)(width, nn.initializers.uniform(1.0), dtype=jnp.float32)(x) \n",
    "    x = hard_not.not_layer(type)(10, dtype=jnp.float32)(x)\n",
    "    x = primitives.nl_ravel(type)(x) \n",
    "    #x = harden_layer.harden_layer(type)(x) \n",
    "    #x = primitives.nl_reshape(type)((10, width))(x) \n",
    "    #x = primitives.nl_sum(type)(-1)(x) \n",
    "    return x\n",
    "\n",
    "def batch_nln(type, x, width):\n",
    "    return jax.vmap(lambda x: nln(type, x, width))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10\n",
    "soft, hard, _ = neural_logic_net.net(lambda type, x: nln(type, x, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    params: {\n",
       "        HardNotLayer_0: {\n",
       "            weights: DeviceArray([[False,  True,  True,  True,  True,  True, False, False,\n",
       "                          False, False],\n",
       "                         [False,  True,  True, False, False, False,  True, False,\n",
       "                           True, False],\n",
       "                         [ True,  True, False,  True,  True,  True, False,  True,\n",
       "                           True, False],\n",
       "                         [False, False, False, False, False, False,  True,  True,\n",
       "                          False,  True],\n",
       "                         [ True,  True, False,  True, False, False, False,  True,\n",
       "                          False, False],\n",
       "                         [False, False,  True, False, False, False,  True, False,\n",
       "                          False, False],\n",
       "                         [ True,  True,  True,  True, False, False,  True,  True,\n",
       "                          False, False],\n",
       "                         [False, False,  True,  True,  True, False, False, False,\n",
       "                          False,  True],\n",
       "                         [ True,  True,  True, False,  True,  True, False,  True,\n",
       "                          False, False],\n",
       "                         [False,  True, False, False, False,  True, False, False,\n",
       "                           True, False]], dtype=bool),\n",
       "        },\n",
       "        HardOrLayer_0: {\n",
       "            weights: DeviceArray([[ True, False, False, ...,  True,  True,  True],\n",
       "                         [False, False, False, ...,  True, False, False],\n",
       "                         [False,  True,  True, ...,  True,  True, False],\n",
       "                         ...,\n",
       "                         [False,  True, False, ...,  True, False, False],\n",
       "                         [False,  True, False, ...,  True,  True, False],\n",
       "                         [ True, False,  True, ..., False, False, False]], dtype=bool),\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "mock_input = harden.harden(jnp.ones([28 * 28]))\n",
    "hard_weights = harden.hard_weights(soft.init(rng, mock_input))\n",
    "hard_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jaxpr = jax.make_jaxpr(lambda x: hard.apply(hard_weights, x))(harden.harden(test_ds['image'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invars: [c]\n",
      "outvars: [g]\n",
      "constvars: [a, b]\n",
      "equation: [a, c] xla_call [d] {'device': None, 'backend': None, 'name': 'hard_or_include', 'donated_invars': (False, False), 'inline': False, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:bool[10,784]\u001b[39m b\u001b[35m:bool[784]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:bool[1,784]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 784)] b\n",
      "    d\u001b[35m:bool[10,784]\u001b[39m = and c a\n",
      "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(d,) }}\n",
      "equation: [d] reduce_or [e] {'axes': (1,)}\n",
      "equation: [b, e] xla_call [f] {'device': None, 'backend': None, 'name': 'hard_not', 'donated_invars': (False, False), 'inline': False, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:bool[10,10]\u001b[39m b\u001b[35m:bool[10]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:bool[1,10]\u001b[39m = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 10)] b\n",
      "    d\u001b[35m:bool[10,10]\u001b[39m = xor c a\n",
      "    e\u001b[35m:bool[10,10]\u001b[39m = not d\n",
      "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(e,) }}\n",
      "equation: [f] reshape [g] {'new_sizes': (100,), 'dimensions': None}\n",
      "\n",
      "jaxpr: { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22ma\u001b[35m:bool[10,784]\u001b[39m b\u001b[35m:bool[10,10]\u001b[39m; c\u001b[35m:bool[784]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "    \u001b[39m\u001b[22m\u001b[22md\u001b[35m:bool[10,784]\u001b[39m = xla_call[\n",
      "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; e\u001b[35m:bool[10,784]\u001b[39m f\u001b[35m:bool[784]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "          \u001b[39m\u001b[22m\u001b[22mg\u001b[35m:bool[1,784]\u001b[39m = broadcast_in_dim[\n",
      "            broadcast_dimensions=(1,)\n",
      "            shape=(1, 784)\n",
      "          ] f\n",
      "          h\u001b[35m:bool[10,784]\u001b[39m = and g e\n",
      "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(h,) }\n",
      "      name=hard_or_include\n",
      "    ] a c\n",
      "    i\u001b[35m:bool[10]\u001b[39m = reduce_or[axes=(1,)] d\n",
      "    j\u001b[35m:bool[10,10]\u001b[39m = xla_call[\n",
      "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; k\u001b[35m:bool[10,10]\u001b[39m l\u001b[35m:bool[10]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
      "          \u001b[39m\u001b[22m\u001b[22mm\u001b[35m:bool[1,10]\u001b[39m = broadcast_in_dim[\n",
      "            broadcast_dimensions=(1,)\n",
      "            shape=(1, 10)\n",
      "          ] l\n",
      "          n\u001b[35m:bool[10,10]\u001b[39m = xor m k\n",
      "          o\u001b[35m:bool[10,10]\u001b[39m = not n\n",
      "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(o,) }\n",
      "      name=hard_not\n",
      "    ] b i\n",
      "    p\u001b[35m:bool[100]\u001b[39m = reshape[dimensions=None new_sizes=(100,)] j\n",
      "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(p,) }\n"
     ]
    }
   ],
   "source": [
    "examine_jaxpr(jaxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_bind(prim, *args, **params):\n",
    "  outvals = prim.bind(*args, **params)\n",
    "  print(\"prim:\", prim.name)\n",
    "  return outvals\n",
    "\n",
    "def eval_jaxpr(jaxpr, consts, *args):\n",
    "  # Mapping from variable -> value\n",
    "  env = {}\n",
    "  \n",
    "  def read(var):\n",
    "    # Literals are values baked into the Jaxpr\n",
    "    if type(var) is core.Literal:\n",
    "      return var.val\n",
    "    return env[var]\n",
    "\n",
    "  def write(var, val):\n",
    "    env[var] = val\n",
    "\n",
    "  # Bind args and consts to environment\n",
    "  safe_map(write, jaxpr.invars, args)\n",
    "  safe_map(write, jaxpr.constvars, consts)\n",
    "\n",
    "  def eval_jaxpr_impl(jaxpr):\n",
    "    # Loop through equations and evaluate primitives using `bind`\n",
    "    for eqn in jaxpr.eqns:\n",
    "      # Read inputs to equation from environment\n",
    "      invals = safe_map(read, eqn.invars)  \n",
    "      # `bind` is how a primitive is called\n",
    "      prim = eqn.primitive\n",
    "      #print(\"prim:\", prim)\n",
    "      #print(\"type:\", type(prim))\n",
    "      if type(prim) is jax.core.CallPrimitive:\n",
    "        #print(\"calling prim:\", prim)\n",
    "        call_jaxpr = eqn.params['call_jaxpr']\n",
    "        safe_map(write, call_jaxpr.invars, map(read, eqn.invars))\n",
    "        eval_jaxpr_impl(call_jaxpr)\n",
    "        safe_map(write, eqn.outvars, map(read, call_jaxpr.outvars))\n",
    "      else:\n",
    "        #print(\"binding prim:\", prim)\n",
    "        # outvals = prim.bind(*invals, **eqn.params)\n",
    "        outvals = symbolic_bind(prim, *invals, **eqn.params)\n",
    "        # Primitives may return multiple outputs or not\n",
    "        if not prim.multiple_results: \n",
    "          outvals = [outvals]\n",
    "        # Write the results of the primitive into the environment\n",
    "        safe_map(write, eqn.outvars, outvals)\n",
    "\n",
    "  # Read the final result of the Jaxpr from the environment\n",
    "  eval_jaxpr_impl(jaxpr)\n",
    "  return safe_map(read, jaxpr.outvars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard_output shape: (100,)\n",
      "hard_output: [False  True  True  True  True  True False False False False False  True\n",
      "  True False False False  True False  True False  True  True False  True\n",
      "  True  True False  True  True False False False False False False False\n",
      "  True  True False  True  True  True False  True False False False  True\n",
      " False False False False  True False False False  True False False False\n",
      "  True  True  True  True False False  True  True False False False False\n",
      "  True  True  True False False False False  True  True  True  True False\n",
      "  True  True False  True False False False  True False False False  True\n",
      " False False  True False]\n",
      "eval_hard_output shape: (100,)\n",
      "eval_hard_output: [False  True  True  True  True  True False False False False False  True\n",
      "  True False False False  True False  True False  True  True False  True\n",
      "  True  True False  True  True False False False False False False False\n",
      "  True  True False  True  True  True False  True False False False  True\n",
      " False False False False  True False False False  True False False False\n",
      "  True  True  True  True False False  True  True False False False False\n",
      "  True  True  True False False False False  True  True  True  True False\n",
      "  True  True False  True False False False  True False False False  True\n",
      " False False  True False]\n"
     ]
    }
   ],
   "source": [
    "hard_mock_input = harden.harden(test_ds['image'][0])\n",
    "hard_output = hard.apply(hard_weights, hard_mock_input)\n",
    "print(\"hard_output shape:\", hard_output.shape)\n",
    "print(\"hard_output:\", hard_output)\n",
    "eval_hard_output = eval_jaxpr(jaxpr.jaxpr, jaxpr.literals, hard_mock_input)\n",
    "print(\"eval_hard_output shape:\", eval_hard_output[0].shape)\n",
    "print(\"eval_hard_output:\", eval_hard_output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
