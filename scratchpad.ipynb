{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 09:59:17.784599: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 09:59:26.842137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 09:59:26.842325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-09 09:59:26.842347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from neurallogic import neural_logic_net, harden, harden_layer, hard_or, hard_and, hard_not, primitives\n",
    "from tests import test_mnist\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax._src.util import safe_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.interpreters import xla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandpit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_jaxpr(closed_jaxpr):\n",
    "   jaxpr = closed_jaxpr.jaxpr\n",
    "   print(\"invars:\", jaxpr.invars)\n",
    "   print(\"outvars:\", jaxpr.outvars)\n",
    "   print(\"constvars:\", jaxpr.constvars)\n",
    "   for eqn in jaxpr.eqns:\n",
    "     print(\"equation:\", eqn.invars, eqn.primitive, eqn.outvars, eqn.params)\n",
    "   print()\n",
    "   print(\"jaxpr:\", jaxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = test_mnist.get_datasets()\n",
    "train_ds[\"image\"] = jnp.reshape(train_ds[\"image\"], (train_ds[\"image\"].shape[0], -1))\n",
    "test_ds[\"image\"] = jnp.reshape(test_ds[\"image\"], (test_ds[\"image\"].shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nln(type, x, width):\n",
    "    x = hard_or.or_layer(type)(width, nn.initializers.uniform(1.0), dtype=jnp.float32)(x) \n",
    "    #x = hard_not.not_layer(type)(10, dtype=jnp.float32)(x)\n",
    "    #x = primitives.nl_ravel(type)(x) \n",
    "    #x = harden_layer.harden_layer(type)(x) \n",
    "    #x = primitives.nl_reshape(type)((10, width))(x) \n",
    "    #x = primitives.nl_sum(type)(-1)(x) \n",
    "    return x\n",
    "\n",
    "def batch_nln(type, x, width):\n",
    "    return jax.vmap(lambda x: nln(type, x, width))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10\n",
    "soft, hard, _ = neural_logic_net.net(lambda type, x: nln(type, x, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    params: {\n",
       "        HardOrLayer_0: {\n",
       "            weights: DeviceArray([[ True, False, False, ...,  True,  True,  True],\n",
       "                         [False, False, False, ...,  True, False, False],\n",
       "                         [False,  True,  True, ...,  True,  True, False],\n",
       "                         ...,\n",
       "                         [False,  True, False, ...,  True, False, False],\n",
       "                         [False,  True, False, ...,  True,  True, False],\n",
       "                         [ True, False,  True, ..., False, False, False]], dtype=bool),\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "mock_input = harden.harden(jnp.ones([28 * 28]))\n",
    "hard_weights = harden.hard_weights(soft.init(rng, mock_input))\n",
    "hard_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jaxpr = jax.make_jaxpr(lambda x: hard.apply(hard_weights, x))(harden.harden(test_ds['image'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invars: [b]\n",
      "outvars: [d]\n",
      "constvars: [a]\n",
      "equation: [a, b] xla_call [c] {'device': None, 'backend': None, 'name': 'hard_or_include', 'donated_invars': (False, False), 'inline': False, 'keep_unused': False, 'call_jaxpr': { lambda ; a:bool[10,784] b:bool[784]. let\n",
      "    c:bool[1,784] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 784)] b\n",
      "    d:bool[10,784] = and c a\n",
      "  in (d,) }}\n",
      "equation: [c] reduce_or [d] {'axes': (1,)}\n",
      "\n",
      "jaxpr: { lambda a:bool[10,784]; b:bool[784]. let\n",
      "    c:bool[10,784] = xla_call[\n",
      "      call_jaxpr={ lambda ; d:bool[10,784] e:bool[784]. let\n",
      "          f:bool[1,784] = broadcast_in_dim[\n",
      "            broadcast_dimensions=(1,)\n",
      "            shape=(1, 784)\n",
      "          ] e\n",
      "          g:bool[10,784] = and f d\n",
      "        in (g,) }\n",
      "      name=hard_or_include\n",
      "    ] a b\n",
      "    h:bool[10] = reduce_or[axes=(1,)] c\n",
      "  in (h,) }\n"
     ]
    }
   ],
   "source": [
    "examine_jaxpr(jaxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax._src.lax_reference as lax_reference\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.logical_and([True, False], [True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.logical_and([True, False], [True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolify(x):\n",
    "    if isinstance(x, bool):\n",
    "        return 'T' if x else 'F'\n",
    "    elif x == 0.0 or x == 1:\n",
    "        return 'T' if x == 1 else 'F'\n",
    "    elif isinstance(x, str) and (x == 'True' or x == 'False'):\n",
    "        return 'T' if x == 'True' else 'F'\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "def stringify(x):\n",
    "    if isinstance(x, numpy.ndarray) or isinstance(x, jax.numpy.ndarray):\n",
    "        return stringify(x.tolist())\n",
    "    elif isinstance(x, list):\n",
    "        return numpy.array([stringify(y) for y in x], dtype=str)\n",
    "    else:\n",
    "        return boolify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', '2', '3'],\n",
       "       ['4', '5', '6']], dtype='<U1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringify([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', '2', '3'],\n",
       "       ['4', '5', '6']], dtype='<U1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringify(numpy.array([[1,2,3], [4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', '2', '3'],\n",
       "       ['4', '5', '6']], dtype='<U1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringify(jax.numpy.array([[1,2,3], [4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hello', 'world', 'hello'],\n",
       "       ['earth', 'hello', 'universe']], dtype='<U8')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringify(numpy.array([[\"hello\",\"world\",\"hello\"], [\"earth\",\"hello\",\"universe\"]], dtype=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['T', 'F', 'T'],\n",
       "       ['T', 'T', 'F']], dtype='<U1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringify(numpy.array([[True,False,True], [True,True,False]], dtype=bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_operator(operator, a, b):\n",
    "  return [operator(x, y) for x, y in zip(a, b)]\n",
    "\n",
    "symbolic_logical_and(a, b):\n",
    "  if \n",
    "\n",
    "def symbolic_and(*args, **kwargs):\n",
    "  if args[0].dtype == bool:\n",
    "    return numpy.logical_and(*args, **kwargs)\n",
    "  else:\n",
    "    print(\"symbolic_and:\")\n",
    "    #print(\"args: \", args)\n",
    "    #print(\"kwargs: \", kwargs)\n",
    "    #print(\"x1 shape = \", numpy.shape(args[0]))\n",
    "    #print(\"x1 = \", args[0])\n",
    "    #print(\"x2 shape = \", numpy.shape(args[1]))\n",
    "    #print(\"x2 = \", args[1])\n",
    "    #return numpy.char.add(*args, **kwargs)\n",
    "    r = binary_operator(lambda a, b: f\"{a} & {b}\", *args, **kwargs)\n",
    "    print(\"result shape = \", numpy.shape(r))\n",
    "    print(\"result = \", r)\n",
    "    return r\n",
    "\n",
    "def symbolic_broadcast_in_dim(*args, **kwargs):\n",
    "  return lax_reference.broadcast_in_dim(*args, **kwargs)\n",
    "\n",
    "def symbolic_xor(x, y):\n",
    "  return f\"{x} ^ {y}\"\n",
    "\n",
    "def symbolic_or(x, y):\n",
    "  return f\"{x} | {y}\"\n",
    "\n",
    "def symbolic_not(x):\n",
    "  return f\"~{x}\"\n",
    "\n",
    "def make_symbolic_reducer(py_binop, init_val):\n",
    "  def reducer(operand, axis=0):\n",
    "    axis = range(numpy.ndim(operand)) if axis is None else axis\n",
    "    result = numpy.full(numpy.delete(numpy.shape(operand), axis), init_val, dtype=numpy.asarray(operand).dtype)\n",
    "    for idx, _ in numpy.ndenumerate(operand):\n",
    "      out_idx = tuple(numpy.delete(idx, axis))\n",
    "      result[out_idx] = py_binop(result[out_idx], operand[idx])\n",
    "    return result\n",
    "  return reducer\n",
    "\n",
    "def symbolic_reduce(operand, init_value, computation, dimensions):\n",
    "  reducer = make_symbolic_reducer(computation, init_value)\n",
    "  return reducer(operand, tuple(dimensions)).astype(operand.dtype)\n",
    "  \n",
    "def symbolic_reduce_or(*args, **kwargs):\n",
    "  if args[0].dtype == bool:\n",
    "    return lax_reference.reduce(*args, init_value=False, dimensions=kwargs['axes'], computation=numpy.logical_or)\n",
    "  else:\n",
    "    return symbolic_reduce(*args, init_value='F', dimensions=kwargs['axes'], computation=symbolic_or)\n",
    "\n",
    "def symbolic_bind(prim, *args, **params):\n",
    "  print(\"primitive: \", prim.name)\n",
    "  symbolic_outvals = {\n",
    "    'and': symbolic_and,\n",
    "    'broadcast_in_dim': symbolic_broadcast_in_dim,\n",
    "    'xor': symbolic_xor,\n",
    "    'not': symbolic_not,\n",
    "    'reshape': lax_reference.reshape,\n",
    "    'reduce_or': symbolic_reduce_or,\n",
    "  }[prim.name](*args, **params)\n",
    "  return symbolic_outvals\n",
    "\n",
    "def eval_jaxpr(symbolic, jaxpr, consts, *args):\n",
    "  # Mapping from variable -> value\n",
    "  env = {}\n",
    "  symbolic_env = {}\n",
    "  \n",
    "  def read(var):\n",
    "    # Literals are values baked into the Jaxpr\n",
    "    if type(var) is core.Literal:\n",
    "      return var.val\n",
    "    return env[var]\n",
    "\n",
    "  def symbolic_read(var):\n",
    "    return symbolic_env[var]\n",
    "\n",
    "  def write(var, val):\n",
    "    env[var] = val\n",
    "\n",
    "  def symbolic_write(var, val):\n",
    "    symbolic_env[var] = val\n",
    "\n",
    "  # Bind args and consts to environment\n",
    "  if not symbolic:\n",
    "    safe_map(write, jaxpr.invars, args)\n",
    "    safe_map(write, jaxpr.constvars, consts)\n",
    "  safe_map(symbolic_write, jaxpr.invars, args)\n",
    "  safe_map(symbolic_write, jaxpr.constvars, consts)\n",
    "\n",
    "  def eval_jaxpr_impl(jaxpr):\n",
    "    # Loop through equations and evaluate primitives using `bind`\n",
    "    for eqn in jaxpr.eqns:\n",
    "      # Read inputs to equation from environment\n",
    "      if not symbolic:\n",
    "        invals = safe_map(read, eqn.invars)  \n",
    "      symbolic_invals = safe_map(symbolic_read, eqn.invars)\n",
    "      # `bind` is how a primitive is called\n",
    "      prim = eqn.primitive\n",
    "      if type(prim) is jax.core.CallPrimitive:\n",
    "        call_jaxpr = eqn.params['call_jaxpr']\n",
    "        if not symbolic:\n",
    "          safe_map(write, call_jaxpr.invars, map(read, eqn.invars))\n",
    "        safe_map(symbolic_write, call_jaxpr.invars, map(symbolic_read, eqn.invars))\n",
    "        eval_jaxpr_impl(call_jaxpr)\n",
    "        if not symbolic:\n",
    "          safe_map(write, eqn.outvars, map(read, call_jaxpr.outvars))\n",
    "        safe_map(symbolic_write, eqn.outvars, map(symbolic_read, call_jaxpr.outvars))\n",
    "      else:\n",
    "        if not symbolic:\n",
    "          outvals = prim.bind(*invals, **eqn.params)\n",
    "        symbolic_outvals = symbolic_bind(prim, *symbolic_invals, **eqn.params)\n",
    "        #if not symbolic:\n",
    "        #  print(f\"outvals: {type(outvals)}: {outvals.shape}: {outvals}\")\n",
    "        #print(f\"symbolic_outvals: {type(symbolic_outvals)}: {symbolic_outvals.shape}: {symbolic_outvals}\")\n",
    "        # Primitives may return multiple outputs or not\n",
    "        if not prim.multiple_results: \n",
    "          if not symbolic:\n",
    "            outvals = [outvals]\n",
    "          symbolic_outvals = [symbolic_outvals]\n",
    "        if not symbolic:\n",
    "          assert numpy.array_equal(numpy.array(outvals), symbolic_outvals)\n",
    "        # Write the results of the primitive into the environment\n",
    "        if not symbolic:\n",
    "          safe_map(write, eqn.outvars, outvals)\n",
    "        safe_map(symbolic_write, eqn.outvars, symbolic_outvals)\n",
    "\n",
    "  # Read the final result of the Jaxpr from the environment\n",
    "  eval_jaxpr_impl(jaxpr)\n",
    "  if not symbolic:\n",
    "    val, symbolic_val = safe_map(read, jaxpr.outvars), safe_map(symbolic_read, jaxpr.outvars)\n",
    "    return val[0], symbolic_val[0]\n",
    "  else:\n",
    "    return safe_map(symbolic_read, jaxpr.outvars)[0]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primitive:  broadcast_in_dim\n",
      "primitive:  and\n",
      "primitive:  reduce_or\n",
      "SUCCESS: jax primitives and symbolic primitives are identical.\n",
      "SUCCESS: non-standard evaluation is identical to standard evaluation of jaxpr.\n",
      "primitive:  broadcast_in_dim\n",
      "primitive:  and\n",
      "symbolic_and:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m symbolic_jaxpr_literals \u001b[39m=\u001b[39m stringify(jaxpr\u001b[39m.\u001b[39mliterals)\n\u001b[1;32m     18\u001b[0m \u001b[39m#print(\"jaxpr.literals = \", symbolic_jaxpr_literals)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m eval_symbolic_output \u001b[39m=\u001b[39m eval_jaxpr(\u001b[39mTrue\u001b[39;49;00m, jaxpr\u001b[39m.\u001b[39;49mjaxpr, symbolic_jaxpr_literals, symbolic_mock_input)\n\u001b[1;32m     20\u001b[0m \u001b[39m# assert the dimensions of eval_hard_output and eval_symbolic_output are the same\u001b[39;00m\n\u001b[1;32m     21\u001b[0m eval_hard_output \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(eval_hard_output)\n",
      "Cell \u001b[0;32mIn[52], line 157\u001b[0m, in \u001b[0;36meval_jaxpr\u001b[0;34m(symbolic, jaxpr, consts, *args)\u001b[0m\n\u001b[1;32m    154\u001b[0m       safe_map(symbolic_write, eqn\u001b[39m.\u001b[39moutvars, symbolic_outvals)\n\u001b[1;32m    156\u001b[0m \u001b[39m# Read the final result of the Jaxpr from the environment\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m eval_jaxpr_impl(jaxpr)\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m symbolic:\n\u001b[1;32m    159\u001b[0m   val, symbolic_val \u001b[39m=\u001b[39m safe_map(read, jaxpr\u001b[39m.\u001b[39moutvars), safe_map(symbolic_read, jaxpr\u001b[39m.\u001b[39moutvars)\n",
      "Cell \u001b[0;32mIn[52], line 133\u001b[0m, in \u001b[0;36meval_jaxpr.<locals>.eval_jaxpr_impl\u001b[0;34m(jaxpr)\u001b[0m\n\u001b[1;32m    131\u001b[0m   safe_map(write, call_jaxpr\u001b[39m.\u001b[39minvars, \u001b[39mmap\u001b[39m(read, eqn\u001b[39m.\u001b[39minvars))\n\u001b[1;32m    132\u001b[0m safe_map(symbolic_write, call_jaxpr\u001b[39m.\u001b[39minvars, \u001b[39mmap\u001b[39m(symbolic_read, eqn\u001b[39m.\u001b[39minvars))\n\u001b[0;32m--> 133\u001b[0m eval_jaxpr_impl(call_jaxpr)\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m symbolic:\n\u001b[1;32m    135\u001b[0m   safe_map(write, eqn\u001b[39m.\u001b[39moutvars, \u001b[39mmap\u001b[39m(read, call_jaxpr\u001b[39m.\u001b[39moutvars))\n",
      "Cell \u001b[0;32mIn[52], line 140\u001b[0m, in \u001b[0;36meval_jaxpr.<locals>.eval_jaxpr_impl\u001b[0;34m(jaxpr)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m symbolic:\n\u001b[1;32m    139\u001b[0m   outvals \u001b[39m=\u001b[39m prim\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39minvals, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39meqn\u001b[39m.\u001b[39mparams)\n\u001b[0;32m--> 140\u001b[0m symbolic_outvals \u001b[39m=\u001b[39m symbolic_bind(prim, \u001b[39m*\u001b[39;49msymbolic_invals, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49meqn\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    141\u001b[0m \u001b[39m#if not symbolic:\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m#  print(f\"outvals: {type(outvals)}: {outvals.shape}: {outvals}\")\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m#print(f\"symbolic_outvals: {type(symbolic_outvals)}: {symbolic_outvals.shape}: {symbolic_outvals}\")\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m# Primitives may return multiple outputs or not\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results: \n",
      "Cell \u001b[0;32mIn[52], line 82\u001b[0m, in \u001b[0;36msymbolic_bind\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msymbolic_bind\u001b[39m(prim, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m     81\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mprimitive: \u001b[39m\u001b[39m\"\u001b[39m, prim\u001b[39m.\u001b[39mname)\n\u001b[0;32m---> 82\u001b[0m   symbolic_outvals \u001b[39m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mand\u001b[39;49m\u001b[39m'\u001b[39;49m: symbolic_and,\n\u001b[1;32m     84\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mbroadcast_in_dim\u001b[39;49m\u001b[39m'\u001b[39;49m: symbolic_broadcast_in_dim,\n\u001b[1;32m     85\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mxor\u001b[39;49m\u001b[39m'\u001b[39;49m: symbolic_xor,\n\u001b[1;32m     86\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mnot\u001b[39;49m\u001b[39m'\u001b[39;49m: symbolic_not,\n\u001b[1;32m     87\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m: lax_reference\u001b[39m.\u001b[39;49mreshape,\n\u001b[1;32m     88\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mreduce_or\u001b[39;49m\u001b[39m'\u001b[39;49m: symbolic_reduce_or,\n\u001b[1;32m     89\u001b[0m   }[prim\u001b[39m.\u001b[39;49mname](\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m     90\u001b[0m   \u001b[39mreturn\u001b[39;00m symbolic_outvals\n",
      "Cell \u001b[0;32mIn[52], line 43\u001b[0m, in \u001b[0;36msymbolic_and\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msymbolic_and:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m#print(\"args: \", args)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m#print(\"kwargs: \", kwargs)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m#print(\"x1 shape = \", numpy.shape(args[0]))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m#print(\"x2 = \", args[1])\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m#return numpy.char.add(*args, **kwargs)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m r \u001b[39m=\u001b[39m binary_operator(\u001b[39mlambda\u001b[39;49;00m a, b: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00ma\u001b[39m}\u001b[39;49;00m\u001b[39m & \u001b[39;49m\u001b[39m{\u001b[39;49;00mb\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mresult shape = \u001b[39m\u001b[39m\"\u001b[39m, numpy\u001b[39m.\u001b[39mshape(r))\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mresult = \u001b[39m\u001b[39m\"\u001b[39m, r)\n",
      "Cell \u001b[0;32mIn[52], line 19\u001b[0m, in \u001b[0;36mbinary_operator\u001b[0;34m(operator, a, b)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbinary_operator\u001b[39m(operator, a, b):\n\u001b[1;32m     16\u001b[0m   \u001b[39m# Reshape a and b to have the same shape, if necessary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m   \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m b\u001b[39m.\u001b[39mshape:\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Reshape a and b to the same number of dimensions\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     a \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mreshape(a\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m[\u001b[39m1\u001b[39;49m \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(b\u001b[39m.\u001b[39;49mshape) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)])\n\u001b[1;32m     20\u001b[0m     b \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mreshape(b\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(a\u001b[39m.\u001b[39mshape) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)])\n\u001b[1;32m     22\u001b[0m     \u001b[39m# Use the vectorized version of the operator to operate on a and b\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (1,1)"
     ]
    }
   ],
   "source": [
    "hard_mock_input = harden.harden(test_ds['image'][0])\n",
    "hard_output = hard.apply(hard_weights, hard_mock_input)\n",
    "#print(\"hard_output shape:\", hard_output.shape)\n",
    "#print(\"hard_output:\", hard_output)\n",
    "eval_hard_output, eval_symbolic_output = eval_jaxpr(False, jaxpr.jaxpr, jaxpr.literals, hard_mock_input)\n",
    "#print(\"eval_hard_output:\", eval_hard_output)\n",
    "#print(\"eval_symbolic_output:\", eval_symbolic_output)\n",
    "assert numpy.array_equal(numpy.array(eval_hard_output), eval_symbolic_output)\n",
    "print(\"SUCCESS: jax primitives and symbolic primitives are identical.\")\n",
    "standard_jax_output = hard.apply(hard_weights, hard_mock_input)\n",
    "#print(\"standard_jax_output\", standard_jax_output)\n",
    "#print(\"eval_hard_output\", numpy.array(eval_hard_output))\n",
    "assert jax.numpy.array_equal(numpy.array(eval_hard_output), standard_jax_output)\n",
    "print(\"SUCCESS: non-standard evaluation is identical to standard evaluation of jaxpr.\")\n",
    "symbolic_mock_input = stringify(hard_mock_input)\n",
    "#print(\"symbolic_mock_input:\", symbolic_mock_input)\n",
    "symbolic_jaxpr_literals = stringify(jaxpr.literals)\n",
    "#print(\"jaxpr.literals = \", symbolic_jaxpr_literals)\n",
    "eval_symbolic_output = eval_jaxpr(True, jaxpr.jaxpr, symbolic_jaxpr_literals, symbolic_mock_input)\n",
    "# assert the dimensions of eval_hard_output and eval_symbolic_output are the same\n",
    "eval_hard_output = numpy.array(eval_hard_output)\n",
    "print(\"eval_hard_output\", eval_hard_output)\n",
    "#print(\"type of eval_hard_output = \", type(eval_hard_output))\n",
    "print(\"eval_symbolic_output:\", eval_symbolic_output)\n",
    "#print(\"type of eval_symbolic_output = \", type(eval_symbolic_output))\n",
    "print(\"shape of eval_hard_output = \", eval_hard_output.shape)\n",
    "print(\"shape of eval_symbolic_output = \", eval_symbolic_output.shape)\n",
    "assert numpy.array_equal(eval_hard_output.shape, eval_symbolic_output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
